#!/usr/bin/env python3
"""
ë¬¸ì„œí™” ë„ìš°ë¯¸ ìŠ¤í¬ë¦½íŠ¸

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” Chicken-RNG í”„ë¡œì íŠ¸ì˜ ë¬¸ì„œí™” ì‘ì—…ì„ ë„ì™€ì¤ë‹ˆë‹¤.
- ìƒˆ ADR ìƒì„±
- ë¬¸ì„œ ë§í¬ ê²€ì¦
- ë¬¸ì„œ ëª©ë¡ ì—…ë°ì´íŠ¸
- ë¬¸ì„œ í†µê³„ ìƒì„±
"""

import argparse
import sys
from datetime import datetime
from pathlib import Path
import re

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì°¾ê¸°
PROJECT_ROOT = Path(__file__).parent.parent
DOCS_DIR = PROJECT_ROOT / "docs"
ADR_DIR = DOCS_DIR / "adr"


def create_new_adr(title: str, author: str) -> Path:
    """ìƒˆë¡œìš´ ADR íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    
    # ë‹¤ìŒ ADR ë²ˆí˜¸ ì°¾ê¸°
    existing_adrs = list(ADR_DIR.glob("*.md"))
    adr_numbers = []
    
    for adr_file in existing_adrs:
        if adr_file.name.startswith(("0", "1", "2", "3", "4", "5", "6", "7", "8", "9")):
            try:
                number = int(adr_file.name[:4])
                adr_numbers.append(number)
            except ValueError:
                continue
    
    next_number = max(adr_numbers, default=0) + 1
    
    # íŒŒì¼ëª… ìƒì„± (titleì„ kebab-caseë¡œ ë³€í™˜)
    title_kebab = re.sub(r'[^a-zA-Z0-9\s-]', '', title.lower())
    title_kebab = re.sub(r'\s+', '-', title_kebab)
    filename = f"{next_number:04d}-{title_kebab}.md"
    
    # í…œí”Œë¦¿ ë¡œë“œ
    template_path = ADR_DIR / "template.md"
    if not template_path.exists():
        print(f"âŒ ADR í…œí”Œë¦¿ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {template_path}")
        sys.exit(1)
    
    template_content = template_path.read_text(encoding='utf-8')
    
    # í…œí”Œë¦¿ ê°’ ì¹˜í™˜
    content = template_content.replace("ADR-XXXX", f"ADR-{next_number:04d}")
    content = content.replace("[ê²°ì • ì œëª©]", title)
    content = content.replace("YYYY-MM-DD", datetime.now().strftime("%Y-%m-%d"))
    content = content.replace("[ì‘ì„±ì ì´ë¦„] ([ì´ë©”ì¼ ë˜ëŠ” GitHub ì•„ì´ë””])", author)
    
    # ìƒˆ ADR íŒŒì¼ ìƒì„±
    new_adr_path = ADR_DIR / filename
    new_adr_path.write_text(content, encoding='utf-8')
    
    print(f"âœ… ìƒˆ ADRì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤: {new_adr_path}")
    return new_adr_path


def validate_doc_links() -> bool:
    """ë¬¸ì„œ ë‚´ ë§í¬ë“¤ì´ ìœ íš¨í•œì§€ ê²€ì¦í•©ë‹ˆë‹¤."""
    
    print("ğŸ” ë¬¸ì„œ ë§í¬ ê²€ì¦ ì¤‘...")
    
    all_docs = list(DOCS_DIR.rglob("*.md"))
    broken_links = []
    
    for doc_path in all_docs:
        content = doc_path.read_text(encoding='utf-8')
        
        # ìƒëŒ€ ë§í¬ ì°¾ê¸° (markdown ë§í¬ì™€ HTML ë§í¬)
        markdown_links = re.findall(r'\[([^\]]+)\]\(([^)]+)\)', content)
        html_links = re.findall(r'<a[^>]+href=[\'"]([^\'"]+)[\'"][^>]*>', content)
        
        for text, link in markdown_links:
            if link.startswith(('http', 'https', 'mailto:')):
                continue  # ì™¸ë¶€ ë§í¬ëŠ” ê±´ë„ˆë›°ê¸°
                
            # ìƒëŒ€ ê²½ë¡œ ë§í¬ ê²€ì¦
            if link.startswith('./') or link.startswith('../') or not link.startswith('/'):
                target_path = (doc_path.parent / link).resolve()
            else:
                # ì ˆëŒ€ ê²½ë¡œ (í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê¸°ì¤€)
                target_path = (PROJECT_ROOT / link.lstrip('/')).resolve()
            
            if not target_path.exists():
                broken_links.append({
                    'file': doc_path.relative_to(PROJECT_ROOT),
                    'link': link,
                    'text': text
                })
    
    if broken_links:
        print("âŒ ê¹¨ì§„ ë§í¬ê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤:")
        for broken in broken_links:
            print(f"  ğŸ“„ {broken['file']}: [{broken['text']}]({broken['link']})")
        return False
    else:
        print("âœ… ëª¨ë“  ë§í¬ê°€ ìœ íš¨í•©ë‹ˆë‹¤!")
        return True


def generate_doc_stats() -> dict:
    """ë¬¸ì„œ í†µê³„ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    
    stats = {
        'total_docs': 0,
        'total_lines': 0,
        'total_words': 0,
        'by_category': {},
        'recent_updates': []
    }
    
    all_docs = list(DOCS_DIR.rglob("*.md"))
    
    for doc_path in all_docs:
        content = doc_path.read_text(encoding='utf-8')
        
        stats['total_docs'] += 1
        lines = len(content.splitlines())
        words = len(content.split())
        
        stats['total_lines'] += lines
        stats['total_words'] += words
        
        # ì¹´í…Œê³ ë¦¬ë³„ ë¶„ë¥˜ (ë””ë ‰í† ë¦¬ ê¸°ì¤€)
        category = doc_path.parent.name if doc_path.parent != DOCS_DIR else 'root'
        if category not in stats['by_category']:
            stats['by_category'][category] = {'docs': 0, 'lines': 0, 'words': 0}
        
        stats['by_category'][category]['docs'] += 1
        stats['by_category'][category]['lines'] += lines
        stats['by_category'][category]['words'] += words
        
        # ìµœê·¼ ìˆ˜ì •ëœ íŒŒì¼ (Git ì •ë³´ê°€ ìˆë‹¤ë©´)
        try:
            import subprocess
            result = subprocess.run(
                ['git', 'log', '-1', '--format=%ci', str(doc_path)],
                capture_output=True,
                text=True,
                cwd=PROJECT_ROOT, check=False
            )
            if result.returncode == 0:
                last_modified = result.stdout.strip()
                stats['recent_updates'].append({
                    'file': doc_path.relative_to(PROJECT_ROOT),
                    'last_modified': last_modified
                })
        except:
            pass  # Git ì •ë³´ ì—†ìŒ
    
    # ìµœê·¼ ì—…ë°ì´íŠ¸ ì •ë ¬
    stats['recent_updates'].sort(key=lambda x: x['last_modified'], reverse=True)
    stats['recent_updates'] = stats['recent_updates'][:10]  # ìµœê·¼ 10ê°œë§Œ
    
    return stats


def print_doc_stats():
    """ë¬¸ì„œ í†µê³„ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤."""
    
    print("ğŸ“Š ë¬¸ì„œ í†µê³„ ìƒì„± ì¤‘...")
    stats = generate_doc_stats()
    
    print("\nğŸ“š ì „ì²´ í†µê³„:")
    print(f"  ğŸ“„ ì´ ë¬¸ì„œ ìˆ˜: {stats['total_docs']}")
    print(f"  ğŸ“ ì´ ë¼ì¸ ìˆ˜: {stats['total_lines']:,}")
    print(f"  ğŸ“– ì´ ë‹¨ì–´ ìˆ˜: {stats['total_words']:,}")
    
    print("\nğŸ“‚ ì¹´í…Œê³ ë¦¬ë³„ í†µê³„:")
    for category, data in stats['by_category'].items():
        print(f"  {category}: {data['docs']}ê°œ ë¬¸ì„œ, {data['lines']:,}ì¤„, {data['words']:,}ë‹¨ì–´")
    
    if stats['recent_updates']:
        print("\nğŸ•’ ìµœê·¼ ì—…ë°ì´íŠ¸ëœ ë¬¸ì„œ (ìƒìœ„ 10ê°œ):")
        for update in stats['recent_updates']:
            print(f"  ğŸ“„ {update['file']} - {update['last_modified'][:10]}")


def update_adr_index():
    """ADR ì¸ë±ìŠ¤ë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤."""
    
    print("ğŸ”„ ADR ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸ ì¤‘...")
    
    # ëª¨ë“  ADR íŒŒì¼ ì°¾ê¸°
    adr_files = sorted([f for f in ADR_DIR.glob("*.md") if f.name != "README.md" and f.name != "template.md"])
    
    if not adr_files:
        print("âš ï¸  ADR íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ADR ì •ë³´ ìˆ˜ì§‘
    adr_list = []
    for adr_file in adr_files:
        content = adr_file.read_text(encoding='utf-8')
        
        # ì œëª© ì¶”ì¶œ
        title_match = re.search(r'^# ADR-(\d{4}): (.+)$', content, re.MULTILINE)
        if not title_match:
            continue
            
        number = title_match.group(1)
        title = title_match.group(2)
        
        # ìƒíƒœ ì¶”ì¶œ
        status_match = re.search(r'## ìƒíƒœ\s*\n\s*([ğŸ”„â­âœ…âŒâ™»ï¸])\s*\*\*([^*]+)\*\*', content, re.MULTILINE)
        status_emoji = status_match.group(1) if status_match else "ğŸ”„"
        status_text = status_match.group(2) if status_match else "Unknown"
        
        # ë‚ ì§œ ì¶”ì¶œ
        date_match = re.search(r'## ë‚ ì§œ\s*\n\s*(\d{4}-\d{2}-\d{2})', content, re.MULTILINE)
        date = date_match.group(1) if date_match else "Unknown"
        
        adr_list.append({
            'number': number,
            'title': title,
            'status_emoji': status_emoji,
            'status_text': status_text,
            'date': date,
            'filename': adr_file.name
        })
    
    # ADR README.md ì—…ë°ì´íŠ¸
    readme_path = ADR_DIR / "README.md"
    if readme_path.exists():
        content = readme_path.read_text(encoding='utf-8')
        
        # í…Œì´ë¸” ì„¹ì…˜ ì°¾ê¸° ë° êµì²´
        table_start = content.find("| ë²ˆí˜¸ | ì œëª© | ìƒíƒœ | ë‚ ì§œ |")
        if table_start != -1:
            table_end = content.find("\n\n", table_start)
            if table_end == -1:
                table_end = len(content)
            
            # ìƒˆ í…Œì´ë¸” ìƒì„±
            new_table_lines = [
                "| ë²ˆí˜¸ | ì œëª© | ìƒíƒœ | ë‚ ì§œ |",
                "|------|------|------|------|"
            ]
            
            for adr in adr_list:
                line = f"| [ADR-{adr['number']}]({adr['filename']}) | {adr['title']} | {adr['status_emoji']} {adr['status_text']} | {adr['date']} |"
                new_table_lines.append(line)
            
            new_table = "\n".join(new_table_lines)
            new_content = content[:table_start] + new_table + content[table_end:]
            
            readme_path.write_text(new_content, encoding='utf-8')
            print(f"âœ… ADR ì¸ë±ìŠ¤ê°€ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤: {len(adr_list)}ê°œ ADR")
        else:
            print("âš ï¸  ADR README.mdì—ì„œ í…Œì´ë¸” ì„¹ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    else:
        print("âŒ ADR README.md íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")


def main():
    parser = argparse.ArgumentParser(description="Chicken-RNG ë¬¸ì„œí™” ë„ìš°ë¯¸")
    subparsers = parser.add_subparsers(dest='command', help='ì‚¬ìš© ê°€ëŠ¥í•œ ëª…ë ¹ì–´')
    
    # ADR ìƒì„± ëª…ë ¹ì–´
    adr_parser = subparsers.add_parser('new-adr', help='ìƒˆ ADR ìƒì„±')
    adr_parser.add_argument('title', help='ADR ì œëª©')
    adr_parser.add_argument('--author', default='ê°œë°œíŒ€', help='ì‘ì„±ì (ê¸°ë³¸ê°’: ê°œë°œíŒ€)')
    
    # ë§í¬ ê²€ì¦ ëª…ë ¹ì–´
    subparsers.add_parser('validate-links', help='ë¬¸ì„œ ë§í¬ ê²€ì¦')
    
    # í†µê³„ ìƒì„± ëª…ë ¹ì–´
    subparsers.add_parser('stats', help='ë¬¸ì„œ í†µê³„ ì¶œë ¥')
    
    # ADR ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸ ëª…ë ¹ì–´
    subparsers.add_parser('update-adr-index', help='ADR ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸')
    
    # ì „ì²´ ì²´í¬ ëª…ë ¹ì–´
    subparsers.add_parser('check-all', help='ëª¨ë“  ê²€ì¦ ì‹¤í–‰')
    
    args = parser.parse_args()
    
    if not args.command:
        parser.print_help()
        return
    
    # docs ë””ë ‰í† ë¦¬ í™•ì¸
    if not DOCS_DIR.exists():
        print(f"âŒ docs ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {DOCS_DIR}")
        sys.exit(1)
    
    # ADR ë””ë ‰í† ë¦¬ í™•ì¸/ìƒì„±
    if not ADR_DIR.exists():
        ADR_DIR.mkdir(parents=True)
        print(f"âœ… ADR ë””ë ‰í† ë¦¬ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤: {ADR_DIR}")
    
    if args.command == 'new-adr':
        create_new_adr(args.title, args.author)
        update_adr_index()
        
    elif args.command == 'validate-links':
        valid = validate_doc_links()
        sys.exit(0 if valid else 1)
        
    elif args.command == 'stats':
        print_doc_stats()
        
    elif args.command == 'update-adr-index':
        update_adr_index()
        
    elif args.command == 'check-all':
        print("ğŸ” ì „ì²´ ë¬¸ì„œ ê²€ì¦ ì‹œì‘...\n")
        
        # 1. ë§í¬ ê²€ì¦
        links_valid = validate_doc_links()
        
        # 2. ADR ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸
        print("\n" + "="*50)
        update_adr_index()
        
        # 3. í†µê³„ ì¶œë ¥
        print("\n" + "="*50)
        print_doc_stats()
        
        print("\n" + "="*50)
        if links_valid:
            print("âœ… ëª¨ë“  ê²€ì¦ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        else:
            print("âš ï¸  ì¼ë¶€ ë¬¸ì œê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤. ìœ„ì˜ ë‚´ìš©ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
            sys.exit(1)


if __name__ == "__main__":
    main() 