"""
íŒŒì¼: dev_tools/event_bank_manager.py
ëª©ì : ëŒ€í˜• ì´ë²¤íŠ¸ ë±…í¬ êµ¬ì¶• ë° ê´€ë¦¬ ë„êµ¬
"""

from __future__ import annotations

import argparse
import json
import shutil
import sys
import tomllib  # Python 3.11+
from collections.abc import Generator
from datetime import datetime
from pathlib import Path
from typing import Any, ClassVar

from tqdm import tqdm

from dev_tools.config import EVENT_CATEGORIES
from game_constants import SCORE_THRESHOLD_HIGH, SCORE_THRESHOLD_MEDIUM

# ì¡°ê±´ë¶€ import ë° ìŠ¤í… í´ë˜ìŠ¤ êµ¬í˜„
try:
    from dev_tools.event_validator import EventValidator

    _EventValidator = EventValidator
except ImportError:

    class _EventValidatorStub:
        """ì´ë²¤íŠ¸ ê²€ì¦ê¸° ìŠ¤í…"""

        def __init__(self) -> None:
            self.errors: list[str] = []

        def validate_event(self, event: dict[str, Any]) -> bool:
            """ì´ë²¤íŠ¸ ê²€ì¦"""
            return True

        def calculate_quality_metrics(self, events: list[dict[str, Any]]) -> dict[str, float]:
            """í’ˆì§ˆ ë©”íŠ¸ë¦­ ê³„ì‚°"""
            return {
                "diversity_score": 0.0,
                "tradeoff_clarity": 0.0,
                "cultural_authenticity": 0.0,
                "replayability": 0.0,
            }

    _EventValidator: type[Any] = _EventValidatorStub  # type: ignore


try:
    from dev_tools.balance_simulator import EventSimulator, SimulationConfig

    _EventSimulator = EventSimulator
    _SimulationConfig = SimulationConfig
except ImportError:

    class _SimulationConfigStub:
        """ì‹œë®¬ë ˆì´ì…˜ ì„¤ì • ìŠ¤í…"""

        def __init__(self, **kwargs: Any) -> None:
            self.iterations = kwargs.get("iterations", 100)
            self.turns_per_sim = kwargs.get("turns_per_sim", 30)
            self.seed = kwargs.get("seed", 42)

    class _EventSimulatorStub:
        """ì´ë²¤íŠ¸ ì‹œë®¬ë ˆì´í„° ìŠ¤í…"""

        def __init__(self, events_dir: str, config: Any) -> None:
            self.events_dir = events_dir
            self.config = config

        def run_simulations(self) -> Any:
            """ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰"""
            return None

        def generate_report(self, results: Any, output_path: str) -> dict[str, Any]:
            """ë³´ê³ ì„œ ìƒì„±"""
            return {
                "bankruptcy_rate": 0.0,
                "avg_days_survived": 0.0,
                "balance_maintained_rate": 0.0,
            }

        def save_report_to_json(self, report_dir: str) -> str:
            """JSON ë³´ê³ ì„œ ì €ì¥"""
            return ""

        def save_report_to_csv(self, report_dir: str) -> str:
            """CSV ë³´ê³ ì„œ ì €ì¥"""
            return ""

    _EventSimulator: type[Any] = _EventSimulatorStub  # type: ignore
    _SimulationConfig: type[Any] = _SimulationConfigStub  # type: ignore


class EventBankManager:
    """ì´ë²¤íŠ¸ ë±…í¬ ê´€ë¦¬ ë„êµ¬"""

    # ì´ë²¤íŠ¸ ì¹´í…Œê³ ë¦¬ ì •ì˜ - config.pyì—ì„œ ê°€ì ¸ì˜¤ë„ë¡ ìˆ˜ì •
    CATEGORIES = EVENT_CATEGORIES

    # ìƒìˆ˜ ì •ì˜
    EVENT_TYPES: ClassVar[list[str]] = ["RANDOM", "THRESHOLD", "SCHEDULED", "CASCADE"]

    def __init__(self) -> None:
        """ì´ˆê¸°í™”"""
        print("ğŸ”§ EventBankManager ì´ˆê¸°í™” ì¤‘...")
        self.events: dict[str, list[dict[str, Any]]] = {
            category: [] for category in self.CATEGORIES
        }
        self.validator = _EventValidator()
        self.simulator = _EventSimulator("", _SimulationConfig())
        self.data_dir = Path("data/events")
        self.out_dir = Path("out")
        self.reports_dir = Path("reports")
        self.validation_errors: list[dict[str, Any]] = []
        self.success_count = 0
        self.failure_count = 0
        self.dry_run = False

        # ë””ë ‰í† ë¦¬ ìƒì„±
        for category in self.CATEGORIES:
            (self.data_dir / category).mkdir(parents=True, exist_ok=True)
        self.out_dir.mkdir(exist_ok=True)
        self.reports_dir.mkdir(exist_ok=True)
        print("âœ… ì´ˆê¸°í™” ì™„ë£Œ")
        sys.stdout.flush()

    def iter_events(self, category: str) -> Generator[dict[str, Any], None, None]:
        """
        ì¹´í…Œê³ ë¦¬ì˜ ì´ë²¤íŠ¸ë¥¼ í•˜ë‚˜ì”© yieldí•˜ëŠ” ì œë„ˆë ˆì´í„°

        Args:
            category: ì´ë²¤íŠ¸ ì¹´í…Œê³ ë¦¬

        Yields:
            ì´ë²¤íŠ¸ ë°ì´í„°
        """
        category_dir = self.data_dir / category
        if not category_dir.exists():
            print(f"âš ï¸ ì¹´í…Œê³ ë¦¬ ë””ë ‰í† ë¦¬ ì—†ìŒ: {category_dir}")
            sys.stdout.flush()
            return

        # TOML íŒŒì¼ ì²˜ë¦¬
        for file_path in category_dir.glob("*.toml"):
            try:
                with open(file_path, "rb") as f:
                    data = tomllib.load(f)
                    events = data.get("events", [])
                    for event in events:
                        event["_source_file"] = str(file_path)
                        yield event
            except Exception as e:
                print(f"âŒ íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜ ({file_path}): {e!s}")
                sys.stdout.flush()

        # JSON íŒŒì¼ ì²˜ë¦¬
        for file_path in category_dir.glob("*.json"):
            try:
                with open(file_path, encoding="utf-8") as f:
                    data = json.load(f)
                    events = data.get("events", [])
                    for event in events:
                        event["_source_file"] = str(file_path)
                        yield event
            except Exception as e:
                print(f"âŒ íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜ ({file_path}): {e!s}")
                sys.stdout.flush()

    def load_all_events(self) -> int:
        """
        ëª¨ë“  ì´ë²¤íŠ¸ ë¡œë“œ

        Returns:
            ë¡œë“œëœ ì´ë²¤íŠ¸ ìˆ˜
        """
        print("ğŸ“‚ ì´ë²¤íŠ¸ ë¡œë“œ ì‹œì‘...")
        sys.stdout.flush()
        total_events = 0

        for category in self.CATEGORIES:
            category_dir = self.data_dir / category
            if not category_dir.exists():
                print(f"âš ï¸ ì¹´í…Œê³ ë¦¬ ë””ë ‰í† ë¦¬ ì—†ìŒ: {category_dir}")
                sys.stdout.flush()
                continue

            # TOML íŒŒì¼ ë¡œë“œ
            toml_files = list(category_dir.glob("*.toml"))
            print(f"ğŸ” '{category}' ì¹´í…Œê³ ë¦¬ì—ì„œ {len(toml_files)}ê°œì˜ TOML íŒŒì¼ ë°œê²¬")
            sys.stdout.flush()

            for file_path in toml_files:
                try:
                    with open(file_path, "rb") as f:
                        data = tomllib.load(f)
                        events = data.get("events", [])
                        if events:
                            self.events[category].extend(events)
                            total_events += len(events)
                            print(f"âœ… {len(events)}ê°œ ì´ë²¤íŠ¸ ë¡œë“œ: {file_path}")
                            sys.stdout.flush()
                except Exception as e:
                    print(f"âŒ íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜ ({file_path}): {e!s}")
                    sys.stdout.flush()

            # JSON íŒŒì¼ ë¡œë“œ
            json_files = list(category_dir.glob("*.json"))
            print(f"ğŸ” '{category}' ì¹´í…Œê³ ë¦¬ì—ì„œ {len(json_files)}ê°œì˜ JSON íŒŒì¼ ë°œê²¬")
            sys.stdout.flush()

            for file_path in json_files:
                try:
                    with open(file_path, encoding="utf-8") as f:
                        data = json.load(f)
                        events = data.get("events", [])
                        if events:
                            self.events[category].extend(events)
                            total_events += len(events)
                            print(f"âœ… {len(events)}ê°œ ì´ë²¤íŠ¸ ë¡œë“œ: {file_path}")
                            sys.stdout.flush()
                except Exception as e:
                    print(f"âŒ íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜ ({file_path}): {e!s}")
                    sys.stdout.flush()

        print(f"ğŸ“Š ì´ {total_events}ê°œ ì´ë²¤íŠ¸ ë¡œë“œ ì™„ë£Œ")
        sys.stdout.flush()
        return total_events

    def validate_all_events(self) -> tuple[int, int]:
        """
        ëª¨ë“  ì´ë²¤íŠ¸ ê²€ì¦

        Returns:
            (ì„±ê³µ ìˆ˜, ì‹¤íŒ¨ ìˆ˜) íŠœí”Œ
        """
        print("ğŸ” ì´ë²¤íŠ¸ ê²€ì¦ ì‹œì‘...")
        sys.stdout.flush()
        self.success_count = 0
        self.failure_count = 0
        self.validation_errors = []

        for category, events in self.events.items():
            print(f"\nğŸ” '{category}' ì¹´í…Œê³ ë¦¬ ì´ë²¤íŠ¸ ê²€ì¦ ì¤‘...")
            sys.stdout.flush()

            # ì§„í–‰ë¥  í‘œì‹œ ì¶”ê°€
            for event in tqdm(events, desc=f"Validating {category}", unit="event"):
                event_id = event.get("id", "unknown")

                # ì´ë²¤íŠ¸ ê²€ì¦
                if self.validator.validate_event(event):
                    self.success_count += 1
                    print(f"âœ… ì´ë²¤íŠ¸ ê²€ì¦ ì„±ê³µ: {event_id}")
                    sys.stdout.flush()
                else:
                    self.failure_count += 1
                    error_info = {
                        "id": event_id,
                        "category": category,
                        "errors": self.validator.errors.copy(),
                        "source_file": event.get("_source_file", "unknown"),
                    }
                    self.validation_errors.append(error_info)
                    print(f"âŒ ì´ë²¤íŠ¸ ê²€ì¦ ì‹¤íŒ¨: {event_id}")
                    print(f"   ì˜¤ë¥˜: {', '.join(self.validator.errors)}")
                    sys.stdout.flush()

        print(f"\nğŸ“Š ê²€ì¦ ê²°ê³¼: ì„±ê³µ {self.success_count}ê°œ, ì‹¤íŒ¨ {self.failure_count}ê°œ")
        sys.stdout.flush()
        return (self.success_count, self.failure_count)

    def save_validation_report(self, report_path: Path | None = None) -> str:
        """
        ê²€ì¦ ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥

        Args:
            report_path: ì €ì¥í•  íŒŒì¼ ê²½ë¡œ (Noneì´ë©´ ìë™ ìƒì„±)

        Returns:
            ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ
        """
        if report_path is None:
            timestamp = datetime.now().strftime("%y%m%d_%H%M%S")
            report_path = self.reports_dir / f"validation_report_{timestamp}.json"

        report = {
            "timestamp": datetime.now().isoformat(),
            "success_count": self.success_count,
            "failure_count": self.failure_count,
            "errors": self.validation_errors,
        }

        if not self.dry_run:
            with open(report_path, "w", encoding="utf-8") as f:
                json.dump(report, f, ensure_ascii=False, indent=2)
            print(f"âœ… ê²€ì¦ ë¦¬í¬íŠ¸ê°€ {report_path}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        else:
            print(f"ğŸ” [DRY RUN] ê²€ì¦ ë¦¬í¬íŠ¸ê°€ {report_path}ì— ì €ì¥ë©ë‹ˆë‹¤.")

        sys.stdout.flush()
        return str(report_path)

    def calculate_quality_metrics(self) -> dict[str, dict[str, float]]:
        """
        ëª¨ë“  ì´ë²¤íŠ¸ì˜ í’ˆì§ˆ ë©”íŠ¸ë¦­ ê³„ì‚°

        Returns:
            ì¹´í…Œê³ ë¦¬ë³„ í’ˆì§ˆ ë©”íŠ¸ë¦­
        """
        print("ğŸ“Š í’ˆì§ˆ ë©”íŠ¸ë¦­ ê³„ì‚° ì‹œì‘...")
        sys.stdout.flush()
        metrics: dict[str, dict[str, float]] = {}

        for category, events in self.events.items():
            if not events:
                print(f"âš ï¸ '{category}' ì¹´í…Œê³ ë¦¬ì— ì´ë²¤íŠ¸ ì—†ìŒ, ê±´ë„ˆëœ€")
                sys.stdout.flush()
                continue

            print(f"\nğŸ“Š '{category}' ì¹´í…Œê³ ë¦¬ í’ˆì§ˆ ë©”íŠ¸ë¦­ ê³„ì‚° ì¤‘...")
            sys.stdout.flush()

            # ì§„í–‰ë¥  í‘œì‹œ ì¶”ê°€
            with tqdm(total=1, desc=f"Calculating metrics for {category}") as pbar:
                category_metrics = self.validator.calculate_quality_metrics(events)
                pbar.update(1)

            metrics[category] = category_metrics

            self._print_metrics(category_metrics)

        return metrics

    def _print_metrics(self, category_metrics: dict[str, float]) -> None:
        for name, score in category_metrics.items():
            status = "âœ…" if score >= SCORE_THRESHOLD_HIGH else "âš ï¸" if score >= SCORE_THRESHOLD_MEDIUM else "âŒ"
            print(f"  {status} {name}: {score:.2f}")
            sys.stdout.flush()

    def run_balance_simulation(self, turns: int = 100, seed: int = 42) -> dict[str, Any]:
        """
        ë°¸ëŸ°ìŠ¤ ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰

        Args:
            turns: ì‹œë®¬ë ˆì´ì…˜í•  í„´ ìˆ˜
            seed: ëœë¤ ì‹œë“œ

        Returns:
            ë°¸ëŸ°ìŠ¤ ë¦¬í¬íŠ¸
        """
        print("ğŸ”„ ë°¸ëŸ°ìŠ¤ ì‹œë®¬ë ˆì´ì…˜ ì‹œì‘...")
        sys.stdout.flush()

        # ëª¨ë“  ì´ë²¤íŠ¸ë¥¼ ì‹œë®¬ë ˆì´í„°ì— ë¡œë“œ
        all_events = []
        for events in self.events.values():
            all_events.extend(events)

        if not all_events:
            print("âŒ ì‹œë®¬ë ˆì´ì…˜í•  ì´ë²¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            sys.stdout.flush()
            return {}

        print(f"\nğŸ”„ {len(all_events)}ê°œ ì´ë²¤íŠ¸ë¡œ {turns}í„´ ì‹œë®¬ë ˆì´ì…˜ ì‹œì‘...")
        sys.stdout.flush()

        # ì‹œë®¬ë ˆì´í„° ì´ˆê¸°í™” ë° ì´ë²¤íŠ¸ ì„¤ì •
        self.simulator = _EventSimulator(str(self.data_dir), _SimulationConfig())

        # ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰ (ì§„í–‰ë¥  í‘œì‹œ ì¶”ê°€)
        with tqdm(total=turns, desc="Simulating turns", unit="turn") as pbar:
            # ì‹¤ì œ ì‹œë®¬ë ˆì´ì…˜ì€ EventSimulator ë‚´ë¶€ì—ì„œ ì‹¤í–‰ë˜ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” ì§„í–‰ë¥ ë§Œ í‘œì‹œ
            results = self.simulator.run_simulations()
            pbar.update(turns)

        # ë°¸ëŸ°ìŠ¤ ë¦¬í¬íŠ¸ ìƒì„±
        report = self.simulator.generate_report(results, "")

        # ê²°ê³¼ ì €ì¥
        timestamp = datetime.now().strftime("%y%m%d_%H%M%S")

        if not self.dry_run:
            if hasattr(self.simulator, "save_report_to_json"):
                json_path = self.simulator.save_report_to_json(str(self.reports_dir))
            else:
                json_path = f"{self.reports_dir}/balance_report_{timestamp}.json"

            if hasattr(self.simulator, "save_report_to_csv"):
                csv_path = self.simulator.save_report_to_csv(str(self.reports_dir))
            else:
                csv_path = f"{self.reports_dir}/metrics_history_{timestamp}.csv"
        else:
            json_path = f"{self.reports_dir}/balance_report_{timestamp}.json"
            csv_path = f"{self.reports_dir}/metrics_history_{timestamp}.csv"
            print(f"ğŸ” [DRY RUN] ë¦¬í¬íŠ¸ê°€ {json_path}ì— ì €ì¥ë©ë‹ˆë‹¤.")
            print(f"ğŸ” [DRY RUN] ë©”íŠ¸ë¦­ íˆìŠ¤í† ë¦¬ê°€ {csv_path}ì— ì €ì¥ë©ë‹ˆë‹¤.")

        # ìš”ì•½ ì¶œë ¥
        print("\nğŸ“Š ë°¸ëŸ°ìŠ¤ ìš”ì•½:")
        sys.stdout.flush()
        if isinstance(report, dict) and "balance_scores" in report:
            balance_scores = report["balance_scores"]
            if isinstance(balance_scores, dict):
                for name, score in balance_scores.items():
                    status = "âœ…" if score >= SCORE_THRESHOLD_HIGH else "âš ï¸" if score >= SCORE_THRESHOLD_MEDIUM else "âŒ"
                    print(f"  {status} {name}: {score:.2f}")
                    sys.stdout.flush()

        print("\nğŸ’¡ ì¶”ì²œì‚¬í•­:")
        sys.stdout.flush()
        if isinstance(report, dict) and "recommendations" in report:
            recommendations = report["recommendations"]
            if isinstance(recommendations, list):
                for recommendation in recommendations:
                    print(f"  â€¢ {recommendation}")
                    sys.stdout.flush()

        return report

    def generate_bank_statistics(self) -> dict[str, Any]:
        """
        ì´ë²¤íŠ¸ ë±…í¬ í†µê³„ ìƒì„±

        Returns:
            í†µê³„ ë°ì´í„°
        """
        print("ğŸ“Š ì´ë²¤íŠ¸ ë±…í¬ í†µê³„ ìƒì„± ì‹œì‘...")
        sys.stdout.flush()

        stats: dict[str, Any] = {
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "total_events": 0,
            "categories": {},
            "types": {},
            "metrics": {},
            "tags": {},
        }

        # ì¹´í…Œê³ ë¦¬ë³„ í†µê³„
        for category, events in self.events.items():
            stats["total_events"] += len(events)
            stats["categories"][category] = len(events)

            # ì§„í–‰ë¥  í‘œì‹œ ì¶”ê°€
            for event in tqdm(events, desc=f"Analyzing {category}", unit="event"):
                # íƒ€ì…ë³„ í†µê³„
                event_type = event.get("type", "UNKNOWN")
                types_dict = stats["types"]
                assert isinstance(types_dict, dict)
                types_dict[event_type] = types_dict.get(event_type, 0) + 1

                # íƒœê·¸ í†µê³„
                tags = event.get("tags", [])
                tags_dict = stats["tags"]
                assert isinstance(tags_dict, dict)
                for tag in tags:
                    tags_dict[tag] = tags_dict.get(tag, 0) + 1

                # ë©”íŠ¸ë¦­ ì˜í–¥ í†µê³„
                effects = event.get("effects", [])
                metrics_dict = stats["metrics"]
                assert isinstance(metrics_dict, dict)
                for effect in effects:
                    metric = effect.get("metric", "UNKNOWN")
                    metrics_dict[metric] = metrics_dict.get(metric, 0) + 1

        print("âœ… í†µê³„ ìƒì„± ì™„ë£Œ")
        sys.stdout.flush()
        return stats

    def export_bank_to_json(self, output_path: Path) -> str:
        """
        ì´ë²¤íŠ¸ ë±…í¬ë¥¼ ë‹¨ì¼ JSON íŒŒì¼ë¡œ ë‚´ë³´ë‚´ê¸°

        Args:
            output_path: ì¶œë ¥ íŒŒì¼ ê²½ë¡œ

        Returns:
            ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ
        """
        print("ğŸ“¤ ì´ë²¤íŠ¸ ë±…í¬ ë‚´ë³´ë‚´ê¸° ì‹œì‘...")
        sys.stdout.flush()

        # ëª¨ë“  ì´ë²¤íŠ¸ë¥¼ í•˜ë‚˜ì˜ ë¦¬ìŠ¤íŠ¸ë¡œ í•©ì¹˜ê¸°
        all_events = []
        for category, events in self.events.items():
            for event in events:
                # _source_file í•„ë“œ ì œê±°
                event_copy = event.copy()
                event_copy.pop("_source_file", None)
                all_events.append(event_copy)

        # ê²°ê³¼ ì €ì¥
        if not self.dry_run:
            with open(output_path, "w", encoding="utf-8") as f:
                json.dump({"events": all_events}, f, ensure_ascii=False, indent=2)
            print(f"âœ… ì´ë²¤íŠ¸ ë±…í¬ê°€ {output_path}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        else:
            print(f"ğŸ” [DRY RUN] ì´ë²¤íŠ¸ ë±…í¬ê°€ {output_path}ì— ì €ì¥ë©ë‹ˆë‹¤.")

        sys.stdout.flush()
        return str(output_path)

    def export_bank_by_category(self, output_dir: Path) -> list[str]:
        """
        ì´ë²¤íŠ¸ ë±…í¬ë¥¼ ì¹´í…Œê³ ë¦¬ë³„ë¡œ ë‚´ë³´ë‚´ê¸°

        Args:
            output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬ ê²½ë¡œ

        Returns:
            ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ ëª©ë¡
        """
        print("ğŸ“¤ ì¹´í…Œê³ ë¦¬ë³„ ì´ë²¤íŠ¸ ë±…í¬ ë‚´ë³´ë‚´ê¸° ì‹œì‘...")
        sys.stdout.flush()

        output_dir.mkdir(exist_ok=True, parents=True)
        saved_files = []

        for category, events in self.events.items():
            if not events:
                print(f"âš ï¸ '{category}' ì¹´í…Œê³ ë¦¬ì— ì´ë²¤íŠ¸ ì—†ìŒ, ê±´ë„ˆëœ€")
                sys.stdout.flush()
                continue

            # _source_file í•„ë“œ ì œê±°
            cleaned_events = []
            for event in events:
                event_copy = event.copy()
                event_copy.pop("_source_file", None)
                cleaned_events.append(event_copy)

            # ê²°ê³¼ ì €ì¥
            output_path = output_dir / f"{category}.json"
            if not self.dry_run:
                with open(output_path, "w", encoding="utf-8") as f:
                    json.dump({"events": cleaned_events}, f, ensure_ascii=False, indent=2)
                print(f"âœ… '{category}' ì¹´í…Œê³ ë¦¬ ì´ë²¤íŠ¸ê°€ {output_path}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
                saved_files.append(str(output_path))
            else:
                print(f"ğŸ” [DRY RUN] '{category}' ì¹´í…Œê³ ë¦¬ ì´ë²¤íŠ¸ê°€ {output_path}ì— ì €ì¥ë©ë‹ˆë‹¤.")
                saved_files.append(str(output_path))

            sys.stdout.flush()

        return saved_files

    def backup_event_bank(self) -> str:
        """
        ì´ë²¤íŠ¸ ë±…í¬ ë°±ì—…

        Returns:
            ë°±ì—… ë””ë ‰í† ë¦¬ ê²½ë¡œ
        """
        print("ğŸ“¦ ì´ë²¤íŠ¸ ë±…í¬ ë°±ì—… ì‹œì‘...")
        sys.stdout.flush()

        # ë°±ì—… ë””ë ‰í† ë¦¬ ìƒì„±
        timestamp = datetime.now().strftime("%y%m%d_%H%M%S")
        backup_dir = self.out_dir / f"backup_{timestamp}"
        backup_dir.mkdir(exist_ok=True, parents=True)

        # ê° ì¹´í…Œê³ ë¦¬ ë””ë ‰í† ë¦¬ ë³µì‚¬
        for category in self.CATEGORIES:
            category_dir = self.data_dir / category
            if category_dir.exists():
                backup_category_dir = backup_dir / category
                if not self.dry_run:
                    shutil.copytree(category_dir, backup_category_dir)
                    print(f"âœ… '{category}' ì¹´í…Œê³ ë¦¬ ë°±ì—… ì™„ë£Œ")
                else:
                    print(f"ğŸ” [DRY RUN] '{category}' ì¹´í…Œê³ ë¦¬ ë°±ì—… ì˜ˆì •")
                sys.stdout.flush()

        print(f"âœ… ë°±ì—…ì´ {backup_dir}ì— ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        sys.stdout.flush()
        return str(backup_dir)

    def merge_event_banks(self, source_dir: Path) -> int:
        """
        ë‹¤ë¥¸ ì´ë²¤íŠ¸ ë±…í¬ ë³‘í•©

        Args:
            source_dir: ì†ŒìŠ¤ ì´ë²¤íŠ¸ ë±…í¬ ë””ë ‰í† ë¦¬

        Returns:
            ë³‘í•©ëœ ì´ë²¤íŠ¸ ìˆ˜
        """
        print(f"ğŸ”„ ì´ë²¤íŠ¸ ë±…í¬ ë³‘í•© ì‹œì‘: {source_dir}")
        sys.stdout.flush()

        if not source_dir.exists():
            print(f"âŒ ì†ŒìŠ¤ ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {source_dir}")
            sys.stdout.flush()
            return 0

        merged_count = 0

        # ê° ì¹´í…Œê³ ë¦¬ ë””ë ‰í† ë¦¬ ì²˜ë¦¬
        for category in self.CATEGORIES:
            source_category_dir = source_dir / category
            if not source_category_dir.exists():
                print(f"âš ï¸ ì†ŒìŠ¤ì— '{category}' ì¹´í…Œê³ ë¦¬ ì—†ìŒ, ê±´ë„ˆëœ€")
                sys.stdout.flush()
                continue

            # TOML íŒŒì¼ ì²˜ë¦¬
            for file_path in source_category_dir.glob("*.toml"):
                target_path = self.data_dir / category / file_path.name
                if target_path.exists():
                    print(f"âš ï¸ ëŒ€ìƒ íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤: {target_path}")
                    sys.stdout.flush()
                    continue

                if not self.dry_run:
                    shutil.copy2(file_path, target_path)
                    print(f"âœ… íŒŒì¼ ë³µì‚¬ ì™„ë£Œ: {file_path.name}")
                else:
                    print(f"ğŸ” [DRY RUN] íŒŒì¼ ë³µì‚¬ ì˜ˆì •: {file_path.name}")
                sys.stdout.flush()
                merged_count += 1

            # JSON íŒŒì¼ ì²˜ë¦¬
            for file_path in source_category_dir.glob("*.json"):
                target_path = self.data_dir / category / file_path.name
                if target_path.exists():
                    print(f"âš ï¸ ëŒ€ìƒ íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤: {target_path}")
                    sys.stdout.flush()
                    continue

                if not self.dry_run:
                    shutil.copy2(file_path, target_path)
                    print(f"âœ… íŒŒì¼ ë³µì‚¬ ì™„ë£Œ: {file_path.name}")
                else:
                    print(f"ğŸ” [DRY RUN] íŒŒì¼ ë³µì‚¬ ì˜ˆì •: {file_path.name}")
                sys.stdout.flush()
                merged_count += 1

        print(f"âœ… ë³‘í•© ì™„ë£Œ: {merged_count}ê°œ íŒŒì¼ ë³‘í•©ë¨")
        sys.stdout.flush()
        return merged_count


def main() -> int:
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description="ì´ë²¤íŠ¸ ë±…í¬ ê´€ë¦¬ ë„êµ¬")
    parser.add_argument(
        "--load", action="store_true", help="ëª¨ë“  ì´ë²¤íŠ¸ ë¡œë“œ ë° í†µê³„ ì¶œë ¥"
    )
    parser.add_argument(
        "--validate", action="store_true", help="ëª¨ë“  ì´ë²¤íŠ¸ ê²€ì¦ ë° ë¦¬í¬íŠ¸ ìƒì„±"
    )
    parser.add_argument(
        "--quality", action="store_true", help="í’ˆì§ˆ ë©”íŠ¸ë¦­ ê³„ì‚°"
    )
    parser.add_argument(
        "--simulate", action="store_true", help="ë°¸ëŸ°ìŠ¤ ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰"
    )
    parser.add_argument(
        "--export", action="store_true", help="ì´ë²¤íŠ¸ ë±…í¬ ë‚´ë³´ë‚´ê¸°"
    )
    parser.add_argument(
        "--backup", action="store_true", help="ì´ë²¤íŠ¸ ë±…í¬ ë°±ì—…"
    )
    parser.add_argument(
        "--merge", type=str, help="ë‹¤ë¥¸ ì´ë²¤íŠ¸ ë±…í¬ ë³‘í•© (ë””ë ‰í† ë¦¬ ê²½ë¡œ)"
    )
    parser.add_argument(
        "--dry-run", action="store_true", help="ì‹¤ì œ íŒŒì¼ ë³€ê²½ ì—†ì´ ì‹¤í–‰"
    )
    parser.add_argument(
        "--output", type=str, default="out", help="ì¶œë ¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’: out)"
    )

    args = parser.parse_args()

    # ê¸°ë³¸ ì‘ì—… ì„¤ì •
    if not any(
        [
            args.load,
            args.validate,
            args.quality,
            args.simulate,
            args.export,
            args.backup,
            args.merge,
        ]
    ):
        args.load = True  # ê¸°ë³¸ ì‘ì—…: ë¡œë“œ

    # ì´ë²¤íŠ¸ ë±…í¬ ê´€ë¦¬ì ì´ˆê¸°í™”
    manager = EventBankManager()
    manager.dry_run = args.dry_run
    manager.out_dir = Path(args.output)
    manager.out_dir.mkdir(exist_ok=True)

    # ì‘ì—… ì‹¤í–‰
    if args.load:
        manager.load_all_events()
        stats = manager.generate_bank_statistics()
        print("\nğŸ“Š ì´ë²¤íŠ¸ ë±…í¬ í†µê³„:")
        sys.stdout.flush()
        for category, count in stats["categories"].items():
            print(f"  â€¢ {category}: {count}ê°œ ì´ë²¤íŠ¸")
            sys.stdout.flush()
        print(f"  [TOTAL] ì´ {stats['total_events']}ê°œ ì´ë²¤íŠ¸")
        sys.stdout.flush()

    if args.validate:
        if not manager.events:
            manager.load_all_events()
        manager.validate_all_events()
        report_path = manager.save_validation_report()
        print(f"ğŸ“„ ê²€ì¦ ë¦¬í¬íŠ¸: {report_path}")
        sys.stdout.flush()

    if args.quality:
        if not manager.events:
            manager.load_all_events()
        metrics = manager.calculate_quality_metrics()
        print("\nğŸ“Š í’ˆì§ˆ ë©”íŠ¸ë¦­ ìš”ì•½:")
        sys.stdout.flush()
        for category, category_metrics in metrics.items():
            print(f"  â€¢ {category}:")
            sys.stdout.flush()
            for name, score in category_metrics.items():
                status = "âœ…" if score >= SCORE_THRESHOLD_HIGH else "âš ï¸" if score >= SCORE_THRESHOLD_MEDIUM else "âŒ"
                print(f"    - {status} {name}: {score:.2f}")
                sys.stdout.flush()

    if args.simulate:
        if not manager.events:
            manager.load_all_events()
        manager.run_balance_simulation()

    if args.export:
        if not manager.events:
            manager.load_all_events()
        # ë‹¨ì¼ íŒŒì¼ë¡œ ë‚´ë³´ë‚´ê¸°
        output_path = manager.out_dir / "all_events.json"
        manager.export_bank_to_json(output_path)
        # ì¹´í…Œê³ ë¦¬ë³„ë¡œ ë‚´ë³´ë‚´ê¸°
        category_dir = manager.out_dir / "categories"
        manager.export_bank_by_category(category_dir)

    if args.backup:
        backup_dir = manager.backup_event_bank()
        print(f"ğŸ“¦ ë°±ì—… ë””ë ‰í† ë¦¬: {backup_dir}")
        sys.stdout.flush()

    if args.merge:
        source_dir = Path(args.merge)
        merged_count = manager.merge_event_banks(source_dir)
        print(f"ğŸ”„ ë³‘í•©ëœ íŒŒì¼ ìˆ˜: {merged_count}")
        sys.stdout.flush()

    return 0


if __name__ == "__main__":
    sys.exit(main())
